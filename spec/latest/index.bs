<pre class="metadata">
Shortname: webvr
Title: WebVR
Group: webvr
Status: ED
ED: https://w3c.github.io/webvr/
Repository: w3c/webvr
Level: 1
Mailing List Archives: https://lists.w3.org/Archives/Public/public-webvr/
Mailing List: public-webvr@mozilla.org

!Participate: <a href="https://github.com/w3c/webvr/issues/new">File an issue</a> (<a href="https://github.com/w3c/webvr/issues">open issues</a>)
!Participate: <a href="https://lists.w3.org/Archives/Public/public-webvr/">Mailing list archive</a>
!Participate: <a href="irc://irc.w3.org:6665/">W3C's #webvr IRC</a>

Editor: Vladimir Vukicevic, Mozilla https://mozilla.org/, vladimir@mozilla.com
Editor: Brandon Jones, Google http://google.com/, bajones@google.com
Editor: Kearwood Gilbert, Mozilla https://mozilla.org/, kgilbert@mozilla.com
Editor: Chris Van Wiemeersch, Mozilla https://mozilla.org/, cvan@mozilla.com
Editor: Nell Waliczek, Microsoft https://microsoft.com/, nell.waliczek@microsoft.com
Editor: Rafael Cintron, Microsoft https://microsoft.com/, rafael.cintron@microsoft.com
Abstract: This specification describes support for accessing virtual reality (VR) devices, including sensors and head-mounted displays on the Web.
</pre>

<pre class="anchors">
urlPrefix: http://www.w3.org/TR/hr-time/
    type: typedef; text: DOMHighResTimeStamp
    type: dfn; text: timestamp origin
urlPrefix: https://wiki.whatwg.org/wiki/OffscreenCanvas
    type: typedef; text: OffscreenCanvas
    type: dfn; text: offscreen canvas
urlPrefix: https://www.w3.org/TR/html51/webappapis.html
    type: dfn; text: window.requestAnimationFrame
urlPrefix: https://www.w3.org/TR/html5/
    type: interface; text: Document
urlPrefix: https://www.khronos.org/registry/webgl/specs/latest/1.0/
    type: typedef; text: uniformMatrix4fv
urlPrefix: https://drafts.fxtf.org/geometry/
    type: interface; text: DOMMatrix

spec: ECMAScript; urlPrefix: https://tc39.github.io/ecma262/#
    type: interface
        text: Promise; url:sec-promise-objects
</pre>

<style>
  .unstable::before {
    content: "This section is not stable.";
    float: right;
    color: red;
  }
  .unstable {
    background-image: url("data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' width='300' height='290'><text transform='rotate(-45)' text-anchor='middle' font-family='sans-serif' font-weight='bold' font-size='70' y='210' opacity='.1'>Unstable</text></svg>");
    background-repeat: repeat
  }

 .unstable.example:not(.no-marker)::before {
     content: "Example " counter(example) " (Unstable)";
     float: none;
 }
</style>


<b style="color: red; font-size: 1.3em">DO NOT IMPLEMENT</b>

<b>The version of the WebVR API represented in this document is incomplete and changing rapidly. Do not attempt to implement it at this time.</b>

<section class="unstable">

Introduction {#intro}
=============

Hardware that enables Virtual Reality applications requires high-precision, low-latency interfaces to deliver an acceptable experience.
Other interfaces, such as device orientation events, can be repurposed to surface VR input but doing so dilutes the interface's original
intent and often does not provide the precision necessary for high-quality VR. The WebVR API provides purpose-built interfaces
to VR hardware to allow developers to build compelling, comfortable VR experiences.


Security, Privacy, and Comfort Considerations {#security}
=============================================

The WebVR API provides powerful new features which bring with them several unique privacy, security, and comfort risks that user agents must take steps to mitigate.

Gaze Tracking {#gazetracking-security}
-------------

While the API does not yet expose eye tracking capabilites a lot can be inferred about where the user is looking by tracking the orientation of their head. This is especially true of VR devices that have limited input capabilities, such as Google Carboard, which frequently require users to control a "gaze cursor" with their head orientation. This means that it may be possible for a malicious page to infer what a user is typing on a virtual keyboard or how they are interacting with a virtual UI based solely on monitoring their head movements. For example: if not prevented from doing so a page could estimate what URL a user is entering into the user agent's URL bar.

To prevent this risk the UA MUST [=blur the active session=] when the users is interacting with sensitive, trusted UI such as URL bars or system dialogs. Additionally, to prevent a malicious page from being able to monitor input on a other pages the UA MUST [=blur the active session=] on non-focused pages.

Trusted Environment {#trustedenvironment-security}
-------------------

If the virtual environment does not consistently track the user's head motion with low latency and at a high frame rate the user may become disoriented or physically ill. Since it is impossible to force pages to produce consistently performant and correct content the UA MUST provide a tracked, trusted environment and a [=VR Compositor=] which runs asynchronously from page content. The compositor is responsible for compositing the trusted and untrusted content. If content is not performant, does not submit frames, or terminates unexpectedly the UA should be able to continue presenting a responsive, trusted UI.

Additionally, page content has the ability to make users uncomfortable in ways not related to performance. Badly applied tracking, strobing colors, and content intended to offend, frighten, or intimidate are examples of content which may cause the user to want to quickly exit the VR experience. Removing the VR device in these cases may not always be a fast or practical option. To accomodate this the UA SHOULD provide users with an action, such as pressing a reserved hardware button or performing a gesture, that escapes out of WebVR content and displays the UA's trusted UI.

When navigating between pages in VR the UA should display trusted UI elements informing the user of the security information of the site they are navigating to which is normally presented by the 2D UI, such as the URL and encryption status.

Context Isolation {#contextisolation-security}
-----------------

The trusted UI must be drawing by an independent rendering context who's state is isolated from any rendering contexts used by the page. (For example, any WebGL rendering contexts.) This is to prevent the page from corrupting the state of the trusted UI's context, which may prevent it from properly rendering a tracked environment. It also prevents the possibility of the page being able to capture imagery from the trusted UI, which could lead to private information being leaked.

Also, to prevent CORS-related vulnerabilities each page will see a new instance of objects returned by the API, such as {{VRDevice}} and {{VRSession}}. Attributes such as the {{VRCanvasLayer/source}} set by one page must not be able to be read by another. Similarly, methods invoked on the API MUST NOT cause an observable state change on other pages. For example: No method will be exposed that enables a system-level orientation reset, as this could be called repeatedly by a malicious page to prevent other pages from tracking properly. The UA MUST, however, respect system-level orientation resets triggered by a user gesture or system menu.


Device Enumeration {#deviceenumeration}
===================

VR {#vr-interface}
----

<pre class="idl">
interface VR : EventTarget {
  // Methods
  Promise&lt;sequence&lt;VRDevice&gt;&gt; getDevices();

  // Events
  attribute EventHandler ondeviceconnect;
  attribute EventHandler ondevicedisconnect;
  attribute EventHandler onnavigate;
};
</pre>

<dfn method for="VR">getDevices()</dfn>
Return a Promise which resolves to a list of available {{VRDevice}}s.

<dfn attribute for="VR">ondeviceconnect</dfn> is an <a>Event handler IDL attribute</a> for the {{deviceconnect}} event type.

<dfn attribute for="VR">ondevicedisconnect</dfn> is an <a>Event handler IDL attribute</a> for the {{devicedisconnect}} event type.

<dfn attribute for="VR">onnavigate</dfn> is an <a>Event handler IDL attribute</a> for the {{navigate}} event type.


VRDevice {#vrdevice-interface}
---------

<pre class="idl">
interface VRDevice : EventTarget {
  // Attributes
  readonly attribute DOMString deviceName;
  readonly attribute boolean isExternal;

  attribute VRSession? activeSession;

  // Methods
  Promise&lt;boolean&gt; supportsSession(VRSessionCreateParametersInit parameters);
  Promise&lt;VRSession&gt; requestSession(VRSessionCreateParametersInit parameters);

  // Events
  attribute EventHandler onsessionchange;
  attribute EventHandler onactivate;
  attribute EventHandler ondeactivate;
};
</pre>

A {{VRDevice}} represents a physical unit of VR hardware that can present imagery to the user somehow. On desktop devices this may take the form of a headset peripheral; on mobile devices it may represent the device itself in conjunction with a viewer harness. It may also represent devices without the ability to present content in stereo but with advanced (6DoF) tracking capabilities.

<dfn attribute for="VRDevice">deviceName</dfn> returns a human readable string describing the {{VRDevice}}.

<dfn attribute for="VRDevice">isExternal</dfn> returns true if the {{VRDevice}} hardware is a separate physical device from the system's main device.

A {{VRDevice}} has an <dfn for="VRDevice">active session</dfn>, initially <code>null</code>, which is the {{VRSession}} that is currently accessing and/or presenting to the device. Only one session per page can be active for a given device at a time.

In order to set or retrieve the [=active session=] a page must <dfn>request a session</dfn> from the device using the <dfn method for="VRDevice">requestSession()</dfn> method. When invoked it MUST return <a>a new Promise</a> |promise| and run the following steps <a>in parallel</a>:

 1. If the requested [=session description=] is not supported by the device, <a>reject</a> |promise| and abort these steps.
 1. If the device's [=active session=] matches the requested [=session description=], <a>resolve</a> |promise| with the [=active session=] and abort these steps.
 1. If the requested [=session description=] requires a user gesture and the algorithm is not <a>triggered by user activation</a> <a>reject</a> |promise| and abort these steps.
 1. If another page has an [=exclusive session=] for the device, <a>reject</a> |promise| and abort these steps.
 1. Let |nextSession| be a new {{VRSession}} which matches the [=session description=].
 1. Let |prevSession| be the current [=active session=].
 1. <a>Fire an event</a> named {{sessionchange}} on the device with it's {{VRSessionEvent/session}} attribute initialized to |nextSession|.
 1. Set the [=active session=] to |nextSession|.
 1. If |prevSession| is not null, [=end the session=].
 1. <a>Resolve</a> |promise| with the [=active session=].

When the <dfn method for="VRDevice">supportsSession()</dfn> method is invoked it MUST return <a>a new Promise</a> |promise| and run the following steps <a>in parallel</a>:

 1. If the requested [=session description=] is supported by the device, <a>resolve</a> |promise| with true.
 1. Else <a>resolve</a> |promise| with false.

The <dfn attribute for="VRDevice">activeSession</dfn> IDL attribute's getter
MUST return the {{VRDevice}}'s [=active session=].

<dfn attribute for="VRDevice">onsessionchange</dfn> is an <a>Event handler IDL attribute</a> for the {{sessionchange}} event type.

<dfn attribute for="VRDevice">onactivate</dfn> is an <a>Event handler IDL attribute</a> for the {{activate}} event type.

<dfn attribute for="VRDevice">ondeactivate</dfn> is an <a>Event handler IDL attribute</a> for the {{deactivate}} event type.


<div class="example">
The following code finds the first available {{VRDevice}}.

<pre highlight="js">
let vrDevice;

navigator.vr.getDevices().then(devices => {
  // Use the first device in the array if one is available. If multiple
  // devices are present, you may want to present the user with a way to
  // select which device to use.
  if (devices.length > 0) {
    vrDevice = devices[0];
  }
});
</pre>
</div>


Session {#session}
=======

VRSession {#vrsession-interface}
---------

<pre class="idl">
interface VRSession : EventTarget {
  // Attributes
  readonly attribute VRDevice device;
  readonly attribute VRSessionCreateParameters createParameters;

  attribute double depthNear;
  attribute double depthFar;
  attribute VRLayer baseLayer;

  // Methods
  VRSourceProperties getSourceProperties(optional double scale);
  Promise&lt;VRFrameOfReference&gt; createFrameOfReference(VRFrameOfReferenceType type);
  VRDevicePose? getDevicePose(VRCoordinateSystem coordinateSystem);
  Promise&lt;void&gt; endSession();

  // Events
  attribute EventHandler onblur;
  attribute EventHandler onfocus;
  attribute EventHandler onresetpose;
};
</pre>

A {{VRSession}} is the interface through with most interaction with a {{VRDevice}} happens. A page must [=request a session=] from the {{VRDevice}}, which may reject the request for a number of reasons. Once a session has been successfully acquired it can be used to [=poll the device pose=], query information about the user's environment and, if it's an [=exclusive session=], define imagery to show on the {{VRDevice}}.

The UA, when possible, SHOULD NOT initialize device tracking or rendering capabilities until a session has been acquired. This is to prevent unwanted side effects of engaging the VR systems when they're not actively being used, such as increased battery usage or related utility applications from appearing when first navigating to a page that only wants to test for the presence of VR hardware in order to advertise VR features. Not all VR platforms offer ways to detect the hardware's presence without initializing tracking, however, so this is only a strong recommendation.

<dfn attribute for="VRSession">device</dfn>

<dfn attribute for="VRSession">createParameters</dfn>

<dfn attribute for="VRSession">depthNear</dfn>

<dfn attribute for="VRSession">depthFar</dfn>

<dfn attribute for="VRSession">baseLayer</dfn>

<dfn method for="VRSession">getSourceProperties()</dfn>

<dfn method for="VRSession">createFrameOfReference()</dfn>

<dfn method for="VRSession">getDevicePose()</dfn>

Issue: Document how to <dfn>poll the device pose</dfn>

<dfn method for="VRSession">endSession()</dfn>

Issue: Document what happens when we <dfn>end the session</dfn>

<dfn attribute for="VRSession">onblur</dfn> is an <a>Event handler IDL attribute</a> for the {{blur}} event type.

<dfn attribute for="VRSession">onfocus</dfn> is an <a>Event handler IDL attribute</a> for the {{focus}} event type.

<dfn attribute for="VRSession">onresetpose</dfn> is an <a>Event handler IDL attribute</a> for the {{resetpose}} event type.

Issue: Document effects when we <dfn>blur the active session</dfn>

Issue: Example of acquiring a session here.

VRSessionCreateParameters {#vrsessioncreateparameters-interface}
-------------------------

The {{VRSessionCreateParameters}} interface

<pre class="idl">
dictionary VRSessionCreateParametersInit {
  required boolean exclusive = true;
};

interface VRSessionCreateParameters {
  readonly attribute boolean exclusive;
};
</pre>

The {{VRSessionCreateParametersInit}} dictionary provides a <dfn>session description</dfn>, indicating the desired capabilities of a session to be returned from {{requestSession()}}.

<dfn attribute for="VRSessionCreateParameters">exclusive</dfn>

Issue: Document restrictions and capabilities of an <dfn>exclusive session</dfn>

The VR Compositor {#compositor}
-----------------

Issue: This needs to be broken up a bit more and more clearly decribe things such as the frame lifecycle.

The UA MUST maintain a <dfn>VR Compositor</dfn> which handles layer composition and frame timing. The compositor MUST use an independent rendering context who's state is isolated from that of the WebGL contexts provided as {{VRCanvasLayer}} sources to prevent the page from corruption the compositor state or reading back content from other pages.

There are no direct interfaces to the compositor, but applications may submit bitmaps to be composited via the layer system and observe the frame timing via calls to {{VRCanvasLayer/commit()}}. The compositor consists of two different loops, assumed to be running in separate threads or processes. The <dfn>Frame Loop</dfn>, which drives the page script, and the <dfn>Render Loop</dfn>, which continuously presents imagery provided by the Frame Loop to the VR device. The render loop maintains it's own copy of the session's layer list. Communication between the two loops is synchronized with a lock that limits access to the render loop's layer list.

Both loops are started when a session is successfully created. The compositor's render loop goes through the following steps:

 1. The layer lock is acquired.
 1. The render loop's layer list images are composited and presented to the device.
 1. The layer lock is released.
 1. Notify the frame loop that a frame has been completed.
 1. return to step 1.

The render loop MUST throttle it's throughput to the refresh rate of the VR device. The exact point in the loop that is most effective to block at may differ between platforms, so no perscription is made for when that should happen.

Upon session creation, the following steps are taken to start the frame loop:

 1. A new promise is created and set as the session's current frame promise. The current frame promise is returned any time {{VRCanvasLayer/commit()}} is called.
 1. The {{sessionchange}} event is fired.
 1. The promise returned from {{requestSession()}} is resolved.

Then, the frame loop performs the following steps while the session is active:

 1. The render loop's layer lock is acquired.
 1. Any dirty layers in the session's layer list are copied to the render loop's layer list.
 1. The render loop's layer lock is released.
 1. Wait for the render loop to signal that a frame has been completed.
 1. The session's current frame promise is set as the the previous frame promise.
 1. A new promise is created and set as the session's current frame promise.
 1. The previous frame promise is resolved.
 1. Once the promise has been resolved, return to step 1.


Pose {#pose}
====

Matrices {#matrices}
--------

WebVR provides various transforms in the form of <dfn lt="matrix|matrices">matrices</dfn>. WebVR matrices are always 4x4 and given as 16 element {{Float32Array}}s in column major order. They may be passed directly to WebGL's {{uniformMatrix4fv}} function, used to create an equivalent {{DOMMatrix}}, or used with a variety of third party math libraries.

Translations specified by WebVR matrices are always given in meters.


VRDevicePose {#vrdevicepose-interface}
-------------

<pre class="idl">
interface VRDevicePose {
  readonly attribute Float32Array leftProjectionMatrix;
  readonly attribute Float32Array leftViewMatrix;

  readonly attribute Float32Array rightProjectionMatrix;
  readonly attribute Float32Array rightViewMatrix;

  readonly attribute Float32Array poseModelMatrix;
};
</pre>

A {{VRDevicePose}} describes the position and orientation of a {{VRDevice}} relative to the {{VRCoordinateSystem}} it was queried with. It also describes the view and projection matrices that should be used by the application to render a frame of a VR scene.

The <dfn attribute for="VRDevicePose">leftProjectionMatrix</dfn> and <dfn attribute for="VRDevicePose">rightProjectionMatrix</dfn>  are [=matrices=] describing the projection to be used for the left and right eye's rendering, respectively. It is highly recommended that applications use this matrix without modification. Failure to use these projection matrices when rendering may cause the presented frame to be distorted or badly aligned, resulting in varying degrees of user discomfort.

The <dfn attribute for="VRDevicePose">leftViewMatrix</dfn> and
<dfn attribute for="VRDevicePose">rightViewMatrix</dfn> are [=matrices=] describing the view transform to be used for the left and right eye's rendering, respectively. The matrices represent the inverse of the model matrix of the associated eye. This value may be passed

<dfn attribute for="VRDevicePose">poseModelMatrix</dfn>


Layers {#layers}
======

VRLayer {#vrlayer-interface}
-------

<pre class="idl">
interface VRLayer {};
</pre>

A {{VRLayer}} defines a source of bitmap images and a description of how the image is to be rendered in the {{VRDevice}}. Initially only one type of layer, the {{VRCanvasLayer}}, is defined but future revisions of the spec may extend the available layer types.

VRCanvasLayer {#vrcanvaslayer-interface}
-------

<pre class="idl">
typedef (HTMLCanvasElement or
         OffscreenCanvas) VRCanvasSource;

[Constructor(VRSession session, optional VRCanvasSource source)]
interface VRCanvasLayer : VRLayer {
  // Attributes
  attribute VRCanvasSource source;

  // Methods
  void setLeftBounds(double left, double bottom, double right, double top);
  FrozenArray&lt;double&gt; getLeftBounds();

  void setRightBounds(double left, double bottom, double right, double top);
  FrozenArray&lt;double&gt; getRightBounds();

  Promise&lt;DOMHighResTimeStamp&gt; commit();
};
</pre>

The <dfn attribute for="VRCanvasLayer">source</dfn> defines a canvas whose contents will be presented by the {{VRDevice}} when {{commit()}} is called.

Upon being set as the source of a {{VRCanvasLayer}} the source's context MAY be lost. Additionally the current backbuffer of the source's context MAY be lost, even if the context was created with the <code>preserveDrawingBuffer</code> context creation attribute set to <code>true</code>.

Note: In order to make use of a canvas in the event of context loss, the application should handle the <code>webglcontextlost</code> event on the source canvas and prevent the event's default behavior. The application should then listen for a <code>webglcontextrestored</code> event to be fired and reload any necessary graphical resources in response.

The layer describes two viewports: the <dfn for="VRCanvasLayer">Left Bounds</dfn> and <dfn for="VRCanvasLayer">Right Bounds</dfn>. Each bounds contians four values (|left|, |bottom|, |right|, |top|) defining the texture bounds within the source canvas to present to the related eye in UV space (0.0 - 1.0) with the bottom left corner of the canvas at (0, 0) and the top right corner of the canvas at (1, 1). If the left bound is greater or equal to the right bound or the bottom bound is greater than or equal to the top bound the viewport is considered to be empty and no content from this layer will be shown on the related eye of the {{VRDevice}}.

The [=left bounds=] MUST default to <code>[0.0, 0.0, 0.5, 1.0]</code> and the [=right bounds=] MUST default to <code>[0.5, 0.0, 1.0, 1.0]</code>.

Invoking the <dfn method for="VRCanvasLayer">setLeftBounds()</dfn> method with a given |left|, |bottom|, |right|, and |top| value sets the values of the [=left bounds=] |left|, |bottom|, |right|, and |top| respectively.

Invoking the <dfn method for="VRCanvasLayer">setRightBounds()</dfn> method with a given |left|, |bottom|, |right|, and |top| value sets the values of the [=right bounds=] |left|, |bottom|, |right|, and |top| respectively.

Invoking the <dfn method for="VRCanvasLayer">getLeftBounds()</dfn> method returns a {{FrozenArray}} of doubles containing the [=left bounds=] to |left|, |bottom|, |right|, and |top| values in that order.

Invoking the <dfn method for="VRCanvasLayer">getRightBounds()</dfn> method returns a {{FrozenArray}} of doubles containing the [=right bounds=] to |left|, |bottom|, |right|, and |top| values in that order.

<dfn method for="VRCanvasLayer">commit()</dfn> captures the {{VRCanvasLayer/source}} canvas's bitmap and submits it to the [=VR compositor=]. Calling {{commit()}} has the same effect on the source canvas as any other operation that uses it's bitmap, and canvases created without <code>preserveDrawingBuffer</code> set to <code>true</code> will be cleared.

Issue: Need an example snippet of a {{VRCanvasLayer}} render loop

VRSourceProperties {#vrsourceproperties-interface}
------------------

<pre class="idl">
interface VRSourceProperties {
  readonly attribute double scale;
  readonly attribute unsigned long width;
  readonly attribute unsigned long height;
};
</pre>

The {{VRSourceProperties}} interface describes the ideal dimensions of a layer image for a {{VRDevice}}, taking into account the native resolution of the device and the distortion required to counteract an distortion introduced by the device's optics.

<dfn attribute for="VRSourceProperties">scale</dfn> returns the scale provided to {{getSourceProperties()}} if one was given. If not, it returns the scale recommended by the system.

<dfn attribute for="VRSourceProperties">width</dfn> and <dfn attribute for="VRSourceProperties">height</dfn> describe the dimensions a layer image should ideally be in order to appear on the device at a {{VRSourceProperties/scale}}:1 pixel ratio. The given dimenions MUST only account for a single eye.

<div class="example">
Because a {{VRCanvasLayer}} contains content for both eyes, the {{VRCanvasLayer/source}} canvas should be twice the size perscribed by the {{VRSourceProperties}} in order to get the desired output.

<pre class="lang-js">
var sourceProperties = vrSession.getSourceProperties();

canvasLayer.source.width = sourceProperties.width * 2;
canvasLayer.source.height = sourceProperties.height;
</pre>
</div>


Coordinate Systems {#coordinatesystems}
==================

Issue: Pretty much nothing in this section is documented

VRCoordinateSystem {#vrcoordinatesystem-interface}
------------------

<pre class="idl">
interface VRCoordinateSystem {
  Float32Array? getTransformTo(VRCoordinateSystem other);
};
</pre>


VRFrameOfReference {#vrframeofreference-interface}
------------------

<pre class="idl">
enum VRFrameOfReferenceType {
  "headModel",
  "eyeLevel",
  "stage",
};

interface VRFrameOfReference : VRCoordinateSystem {
  readonly attribute VRStageBounds? bounds;
};
</pre>


VRStageBounds {#vrstagebounds-interface}
----------------

<pre class="idl">
interface VRStageBounds {
  readonly attribute double minX;
  readonly attribute double maxX;
  readonly attribute double minZ;
  readonly attribute double maxZ;
};
</pre>

The {{VRStageBounds}} interface describes a space known as a "<dfn for="VRStageBounds">Stage</dfn>". The [=stage=] is a bounded, floor relative play space that the user can be expected to safely be able to move within. Other VR platforms sometimes refer to this concept as "room scale" or "standing VR".

<dfn attribute for="VRStageBounds">minX</dfn>, <dfn attribute for="VRStageBounds">maxX</dfn>, <dfn attribute for="VRStageBounds">minZ</dfn>, and <dfn attribute for="VRStageBounds">maxZ</dfn> define an axis-aligned rectangle on the floor relative to the origin of the {{VRCoordinateSystem}} the bounds were queried with. Bounds are specified in meters. The origin MAY be outside the bounds rectangle. {{minX}} MUST be less than {{maxX}} and {{minZ}} MUST be less than {{maxZ}}.

Note: Content should not require the user to move beyond these bounds; however, it is possible for the user to ignore the bounds resulting in position values outside of the rectangle they describe if their physical surroundings allow for it.


Events {#events}
========

VRDeviceEvent {#vrdeviceevent-interface}
-------

<pre class="idl">
[Constructor(DOMString type, VRDeviceEventInit eventInitDict)]
interface VRDeviceEvent : Event {
  readonly attribute VRDevice device;
};

dictionary VRDeviceEventInit : EventInit {
  required VRDevice device;
};
</pre>

<dfn attribute for="VRDeviceEvent">device</dfn>
The {{VRDevice}} associated with this event.

<dfn attribute for="VRDeviceEvent">session</dfn>
The {{VRSession}} associated with this event, if any.

VRSessionEvent {#vrsessionevent-interface}
-------

<pre class="idl">
[Constructor(DOMString type, VRSessionEventInit eventInitDict)]
interface VRSessionEvent : Event {
  readonly attribute VRSession session;
};

dictionary VRSessionEventInit : EventInit {
  required VRSession session;
};
</pre>

<dfn attribute for="VRSessionEvent">session</dfn>
The {{VRSession}} associated with this event.

Event Types {#event-types}
-----------

The UA MUST provide the following new events. Registration for and firing of the events must follow the usual behavior of DOM4 Events.

The UA MAY fire a <dfn event for="VR">deviceconnect</dfn> event on the {{VR}} object to indicate that a {{VRDevice}} has been connected. The event MUST be of type {{VRDeviceEvent}}.

The UA MAY dispatch a <dfn event for="VR">devicedisconnect</dfn> event on the {{VR}} object to indicate that a {{VRDevice}} has been disconnected. The event MUST be of type {{VRDeviceEvent}}.

The UA MAY dispatch a <dfn event for="VR">navigate</dfn> event on the {{VR}} object to indicate that the current page has been navigated to from a browsing context that was actively presenting VR content. The event's {{VRSessionEvent/session}} MUST be an instance of a {{VRSession}} with identical capabilities to the [=active session=] from the previous page, such that presenting to the session will feel like a seamless transition to the user. The event MUST be of type {{VRSessionEvent}}.

The UA MUST dispatch a <dfn event for="VRDevice">sessionchange</dfn> event on a {{VRDevice}} to indicate that the {{VRDevice}} has begun or ended a new {{VRSession}}. This event should not fire on subsequent calls to {{requestSession()}} if the returned session is the same as the current {{activeSession}}. The event MUST be of type {{VRSessionEvent}}.

The UA MAY dispatch a <dfn event for="VRDevice">activate</dfn> event on a {{VRDevice}} to indicate that something has occurred which suggests the {{VRDevice}} should be begin an [=exclusive session=]. For example, if the {{VRDevice}} is capable of detecting when the user has put it on, this event SHOULD fire when they do so. The event MUST be of type {{VRDeviceEvent}}.

The UA MAY dispatch a <dfn event for="VRDevice">deactivate</dfn> event on a {{VRDevice}} to indicate that something has occurred which suggests the {{VRDevice}} should end the active session. For example, if the {{VRDevice}} is capable of detecting when the user has taken it off, this event SHOULD fire when they do so. The event MUST be of type {{VRDeviceEvent}}.

A UA MAY dispatch a <dfn event for="VRSession">blur</dfn> event on a {{VRSession}} to indicate that presentation to the {{VRSession}} by the page has been suspended by the UA, OS, or VR hardware. While a {{VRSession}} is blurred it remains active but it may have it's frame production throttled. This is to prevent tracking while the user interacts with potentially sensitive UI. For example: The UA SHOULD blur the presenting application when the user is typing a URL into the browser with a virtual keyboard, otherwise the presenting page may be able to guess the URL the user is entering by tracking their head motions. The event MUST be of type {{VRSessionEvent}}.

A UA MAY dispatch a <dfn event for="VRSession">focus</dfn> event on a {{VRSession}} to indicate that presentation to the {{VRSession}} by the page has resumed after being suspended. The event MUST be of type {{VRSessionEvent}}.

A UA MUST dispatch a <dfn event for="VRSession">resetpose</dfn> event on a {{VRSession}} when the system resets the {{VRDevice}}'s position or orientation. The event MUST be of type {{VRSessionEvent}}.

Navigator interface extension {#navigator-interface}
=============================

Issue: Navigator interface is all alone. :( Does this belong somewhere else, or is this reasonable? This is about how WebUSB and WebBluetooth handle it.

<pre class="idl">
partial interface Navigator {
  [SameObject] readonly attribute VR vr;
};
</pre>


Acknowledgements {#ack}
===================

The following individuals have contributed to the design of the WebVR standard:

* Sebastian Sylvan, Microsoft https://microsoft.com/, ssylvan@microsoft.com

</section>
